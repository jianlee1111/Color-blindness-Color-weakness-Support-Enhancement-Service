# -*- coding: utf-8 -*-
"""image_crawling

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TjBI5OKEfcWi3UEU0z6kfk-9H-sKxN_M
"""

!pip install beautifulsoup4

from google.colab import drive
drive.mount('/content/drive')

import sys
!sudo add-apt-repository ppa:saiarcot895/chromium-beta -y
!sudo apt remove chromium-browser -y
!sudo snap remove chromium -y
!sudo apt install chromium-browser -y

!pip install selenium
!apt-get update
!apt install chromium-chromedriver -y
!cp /usr/lib/chromium-browser/chromedriver /usr/bin/
sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')

import time
import os
from urllib.request import urlretrieve
from urllib.parse import quote_plus
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service

def createFolder(dir):
    try:
        if not os.path.exists(dir):
            os.makedirs(dir)
    except OSError:
        print('Error: Creating directory. '+dir)


search = input("키워드를 입력하시오. ")
url = f'https://www.google.co.kr/search?tbm=isch&q={quote_plus(search)}'


#chrome_options=webdriver.ChromeOptions()
#service=Service(executable_path=ChromeDriverManager().install())
#options = webdriver.ChromeOptions()
#chrome_option.add_experimental_option("detach", True)
#chrome_option.add_experimental_option("excludeSwitches", ["enable-logging"])
#driver = webdriver.Chrome('chromedriver', options=options)

options = webdriver.ChromeOptions()
options.add_argument('--headless') # 화면 출력 x
options.add_argument('--no-sandbox') # ?
options.add_argument('--disable-dev-shm-usage') # /deb/shm 디렉토리를 사용하지 않음 공유메모리를 담당
webdriver_service=Service('/usr/bin/chromedriver')
driver = webdriver.Chrome(service=webdriver_service, options=options)

driver.implicitly_wait(3)
driver.get(url)

num=2
for i in range(num):
    driver.execute_script("window.scrollBy(0,5000)")

html = driver.page_source
soup = BeautifulSoup(html,'html.parser')

img = soup.select('.rg_i.Q4LuWd')

n=1
imgurl = []

for i in img:
    try:
        imgurl.append(i.attrs["src"])
    except KeyError:
        imgurl.append(i.attrs["data-src"])

for i in imgurl:
    dir="/content/drive/MyDrive/Colab Notebooks/images/"+search
    createFolder(dir)
    urlretrieve(i, dir+"/"+search+str(n)+".jpg")
    n+=1

driver.close()